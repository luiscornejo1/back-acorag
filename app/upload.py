"""
MÃ³dulo para subir documentos nuevos y hacer ingesta en tiempo real
Soporta: PDF, TXT, JSON, DOCX
"""
import os
import json
import tempfile
from typing import Optional, Dict, Any, List
from datetime import datetime
import hashlib

# PDF extraction
try:
    import PyPDF2
    HAS_PDF = True
except ImportError:
    HAS_PDF = False

# DOCX extraction
try:
    from docx import Document as DocxDocument
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

from sentence_transformers import SentenceTransformer
from app.utils import get_db_connection


class DocumentUploader:
    """Maneja la carga y procesamiento de documentos nuevos"""
    
    def __init__(self):
        self.model = SentenceTransformer(
            os.getenv("EMBEDDING_MODEL", "hiiamsid/sentence_similarity_spanish_es")
        )
        self.chunk_size = int(os.getenv("CHUNK_SIZE", "1000"))
        self.chunk_overlap = int(os.getenv("CHUNK_OVERLAP", "200"))
    
    def extract_text_from_pdf(self, file_path: str) -> str:
        """Extrae texto de un PDF"""
        if not HAS_PDF:
            raise ImportError("PyPDF2 no estÃ¡ instalado. Ejecuta: pip install PyPDF2")
        
        text = ""
        try:
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
        except Exception as e:
            raise Exception(f"Error extrayendo texto de PDF: {e}")
        
        return text.strip()
    
    def extract_text_from_docx(self, file_path: str) -> str:
        """Extrae texto de un DOCX"""
        if not HAS_DOCX:
            raise ImportError("python-docx no estÃ¡ instalado. Ejecuta: pip install python-docx")
        
        try:
            doc = DocxDocument(file_path)
            text = "\n".join([paragraph.text for paragraph in doc.paragraphs])
            return text.strip()
        except Exception as e:
            raise Exception(f"Error extrayendo texto de DOCX: {e}")
    
    def extract_text_from_txt(self, file_path: str) -> str:
        """Lee texto plano"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read().strip()
        except Exception as e:
            raise Exception(f"Error leyendo archivo TXT: {e}")
    
    def extract_text(self, file_path: str, file_type: str) -> str:
        """Extrae texto segÃºn el tipo de archivo"""
        if file_type == "pdf":
            return self.extract_text_from_pdf(file_path)
        elif file_type == "docx":
            return self.extract_text_from_docx(file_path)
        elif file_type == "txt":
            return self.extract_text_from_txt(file_path)
        elif file_type == "json":
            # Para JSON, leer y extraer campos relevantes
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Si es un objeto con campos, extraerlos
                if isinstance(data, dict):
                    return json.dumps(data, indent=2, ensure_ascii=False)
                return str(data)
        else:
            raise ValueError(f"Tipo de archivo no soportado: {file_type}")
    
    def chunk_text(self, text: str) -> List[str]:
        """Divide el texto en chunks con overlap"""
        if len(text) <= self.chunk_size:
            return [text]
        
        chunks = []
        start = 0
        while start < len(text):
            end = start + self.chunk_size
            chunk = text[start:end]
            
            # Intentar cortar en un punto natural (., !, ?, \n)
            if end < len(text):
                last_period = max(
                    chunk.rfind('.'),
                    chunk.rfind('!'),
                    chunk.rfind('?'),
                    chunk.rfind('\n')
                )
                if last_period > self.chunk_size * 0.5:
                    chunk = chunk[:last_period + 1]
                    end = start + last_period + 1
            
            chunks.append(chunk.strip())
            start = end - self.chunk_overlap
        
        return chunks
    
    def generate_document_id(self, filename: str, content: str) -> str:
        """Genera un ID Ãºnico para el documento"""
        hash_input = f"{filename}_{content[:100]}_{datetime.now().isoformat()}"
        return hashlib.md5(hash_input.encode()).hexdigest()
    
    def ingest_document(
        self,
        file_path: str,
        filename: str,
        file_type: str,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Ingesta un documento completo:
        1. Extrae texto
        2. Divide en chunks
        3. Genera embeddings
        4. Guarda en PostgreSQL
        
        Returns:
            Dict con informaciÃ³n del documento ingestado
        """
        try:
            # 1. Extraer texto
            print(f"ðŸ“„ Extrayendo texto de {filename}...")
            text = self.extract_text(file_path, file_type)
            
            if not text or len(text) < 10:
                raise ValueError("El documento estÃ¡ vacÃ­o o tiene muy poco contenido")
            
            # 2. Generar ID Ãºnico
            doc_id = self.generate_document_id(filename, text)
            
            # 3. Preparar metadata
            if metadata is None:
                metadata = {}
            
            metadata.update({
                "filename": filename,
                "file_type": file_type,
                "upload_date": datetime.now().isoformat(),
                "text_length": len(text),
            })
            
            # 4. Conectar a la base de datos
            conn = get_db_connection()
            cursor = conn.cursor()
            
            # 5. Verificar si el documento ya existe
            cursor.execute(
                "SELECT document_id FROM documents WHERE document_id = %s",
                (doc_id,)
            )
            if cursor.fetchone():
                raise ValueError(f"El documento ya existe en la base de datos (ID: {doc_id})")
            
            # 6. Insertar documento
            print(f"ðŸ’¾ Guardando documento en la base de datos...")
            cursor.execute("""
                INSERT INTO documents (document_id, metadata, created_at)
                VALUES (%s, %s, NOW())
                RETURNING id
            """, (doc_id, json.dumps(metadata)))
            
            db_doc_id = cursor.fetchone()[0]
            
            # 7. Dividir en chunks
            print(f"âœ‚ï¸  Dividiendo texto en chunks...")
            chunks = self.chunk_text(text)
            print(f"   â†’ {len(chunks)} chunks generados")
            
            # 8. Generar embeddings e insertar chunks
            print(f"ðŸ”¢ Generando embeddings...")
            for idx, chunk in enumerate(chunks):
                # Generar embedding
                embedding = self.model.encode(chunk).tolist()
                
                # Insertar chunk
                cursor.execute("""
                    INSERT INTO document_chunks (
                        document_id,
                        chunk_index,
                        content,
                        embedding,
                        metadata
                    )
                    VALUES (%s, %s, %s, %s, %s)
                """, (
                    db_doc_id,
                    idx,
                    chunk,
                    embedding,
                    json.dumps({"chunk_length": len(chunk)})
                ))
            
            # 9. Commit
            conn.commit()
            cursor.close()
            conn.close()
            
            print(f"âœ… Documento ingestado exitosamente!")
            
            return {
                "success": True,
                "document_id": doc_id,
                "db_id": db_doc_id,
                "filename": filename,
                "chunks_created": len(chunks),
                "text_length": len(text),
                "metadata": metadata
            }
        
        except Exception as e:
            if 'conn' in locals():
                conn.rollback()
                conn.close()
            raise Exception(f"Error en la ingesta: {str(e)}")


def upload_and_ingest(
    file_content: bytes,
    filename: str,
    metadata: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """
    FunciÃ³n helper para subir un archivo desde bytes
    
    Args:
        file_content: Contenido del archivo en bytes
        filename: Nombre original del archivo
        metadata: Metadata opcional del documento
    
    Returns:
        Dict con resultado de la ingesta
    """
    # Determinar tipo de archivo
    file_ext = filename.split('.')[-1].lower()
    if file_ext not in ['pdf', 'txt', 'docx', 'json']:
        raise ValueError(f"Tipo de archivo no soportado: {file_ext}")
    
    # Guardar temporalmente
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_ext}") as tmp_file:
        tmp_file.write(file_content)
        tmp_path = tmp_file.name
    
    try:
        # Ingestar
        uploader = DocumentUploader()
        result = uploader.ingest_document(tmp_path, filename, file_ext, metadata)
        return result
    finally:
        # Limpiar archivo temporal
        if os.path.exists(tmp_path):
            os.remove(tmp_path)
