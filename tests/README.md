# ğŸ§ª Tests - Aconex RAG System

Esta carpeta contiene todos los tests automatizados del sistema RAG de Aconex.

## ğŸ“ Estructura

```
tests/
â”œâ”€â”€ __init__.py              # Package marker
â”œâ”€â”€ conftest.py              # Fixtures y configuraciÃ³n compartida
â”œâ”€â”€ test_ingest.py           # Tests de ingesta de documentos
â”œâ”€â”€ test_search.py           # Tests de bÃºsqueda semÃ¡ntica
â”œâ”€â”€ test_upload.py           # Tests de carga de archivos
â”œâ”€â”€ test_utils.py            # Tests de utilidades
â””â”€â”€ test_api.py              # Tests de endpoints API
```

## ğŸš€ Quick Start

### Ejecutar todos los tests
```powershell
pytest tests/ -v
```

### Ejecutar con cobertura
```powershell
pytest tests/ --cov=app --cov-report=html
```

### Usar el script helper
```powershell
.\run_tests.ps1 cov
```

## ğŸ“Š Cobertura de Tests

| MÃ³dulo | Tests | Cobertura Objetivo |
|--------|-------|-------------------|
| `app/ingest.py` | 25+ tests | >= 85% |
| `app/search_core.py` | 20+ tests | >= 90% |
| `app/upload.py` | 18+ tests | >= 80% |
| `app/utils.py` | 15+ tests | >= 95% |
| `app/api.py` | 25+ tests | >= 75% |
| **TOTAL** | **100+ tests** | **>= 80%** |

## ğŸ¯ CategorÃ­as de Tests

### Por Markers

- `@pytest.mark.unit` - Tests unitarios (funciones aisladas)
- `@pytest.mark.integration` - Tests de integraciÃ³n (mÃºltiples componentes)
- `@pytest.mark.api` - Tests de endpoints REST
- `@pytest.mark.db` - Tests que requieren base de datos
- `@pytest.mark.mock` - Tests que usan mocks extensivamente
- `@pytest.mark.slow` - Tests que toman > 1 segundo

### Ejecutar por categorÃ­a

```powershell
pytest tests/ -m "unit" -v          # Solo unitarios
pytest tests/ -m "integration" -v   # Solo integraciÃ³n
pytest tests/ -m "api" -v           # Solo API
```

## ğŸ› ï¸ Fixtures Disponibles

Ver `conftest.py` para la lista completa. Principales:

- `test_env_vars` - Variables de entorno para tests
- `mock_db_connection` - Mock de PostgreSQL
- `mock_sentence_transformer` - Mock del modelo de embeddings
- `sample_aconex_document` - Documento Aconex de prueba
- `test_client` - Cliente FastAPI para tests

## ğŸ“– DocumentaciÃ³n

- [TESTING_STRATEGY.md](../TESTING_STRATEGY.md) - Estrategia completa
- [TESTING_GUIDE.md](../TESTING_GUIDE.md) - GuÃ­a de ejecuciÃ³n
- [requirements-test.txt](../requirements-test.txt) - Dependencias

## ğŸ” Escenarios Cubiertos

### âœ… Ingesta (test_ingest.py)
- Lectura de JSON/NDJSON
- NormalizaciÃ³n de documentos Aconex
- GeneraciÃ³n de embeddings
- InserciÃ³n en BD
- DeduplicaciÃ³n
- Flujo completo end-to-end

### âœ… BÃºsqueda (test_search.py)
- BÃºsqueda vectorial bÃ¡sica
- Filtros por project_id
- Ranking hÃ­brido
- Threshold de relevancia
- Casos edge (queries vacÃ­os, caracteres especiales)

### âœ… Upload (test_upload.py)
- ExtracciÃ³n de texto (PDF, TXT, DOCX, JSON)
- Chunking adaptativo
- Ingesta en tiempo real
- DetecciÃ³n de duplicados
- Almacenamiento de file_content

### âœ… API (test_api.py)
- POST /search
- POST /chat
- POST /upload
- GET /health
- GET /document/{id}/file
- Manejo de errores
- ValidaciÃ³n de parÃ¡metros

### âœ… Utilidades (test_utils.py)
- ConexiÃ³n a BD
- Chunking de texto
- Manejo de configuraciÃ³n

## ğŸ’¡ Tips

### Durante Desarrollo
```powershell
# Parar en el primer error
pytest tests/ -x -v

# Ver prints en tests
pytest tests/ -s -v

# Test especÃ­fico
pytest tests/test_ingest.py::test_normalize_doc_complete -v
```

### Antes de Commit
```powershell
# Verificar todo
.\run_tests.ps1 cov

# O manualmente
pytest tests/ --cov=app --cov-fail-under=80
```

### CI/CD
```powershell
pytest tests/ --cov=app --cov-report=xml --junit-xml=test-results.xml
```

## ğŸ› Troubleshooting

**Error: No module named 'app'**
```powershell
# AsegÃºrate de estar en backend-acorag/
cd backend-acorag
pytest tests/ -v
```

**Tests muy lentos**
```powershell
# Ejecutar en paralelo
pytest tests/ -n auto
```

**Ver solo tests fallidos**
```powershell
pytest tests/ --lf -v
```

## ğŸ“ˆ MÃ©tricas de Calidad

- âœ… **100+ tests** automatizados
- âœ… **>= 80%** cobertura de cÃ³digo
- âœ… **< 2 minutos** tiempo total de ejecuciÃ³n
- âœ… **0 warnings** en ejecuciÃ³n limpia
- âœ… **Todos los escenarios crÃ­ticos** cubiertos

## ğŸ¤ Contribuir

Al agregar nuevas funcionalidades:

1. Escribe tests ANTES de implementar (TDD)
2. Usa fixtures existentes cuando sea posible
3. Marca los tests con decoradores apropiados
4. Verifica que la cobertura no baje
5. Documenta escenarios edge cases

---

**Ãšltima actualizaciÃ³n:** 2025-11-24  
**VersiÃ³n:** 1.0
